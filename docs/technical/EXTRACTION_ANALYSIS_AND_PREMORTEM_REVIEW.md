# Analysis: Extraction Layer & Pre-Mortem Review

**Date:** 2026-02-21
**Status:** Strategic Review Complete
**Focus:** Voice-to-Structured-Data (Phase 1)

---

## 1. Executive Summary

The uncommitted documentation and the initial implementation in `src/extraction/` represent a significant leap toward a professional-grade clinical platform. The architecture transitions from a simple AI wrapper to a **High-Assurance "Compliance Officer"** model.

The addition of `docs/PRE_MORTEM.md` is particularly valuable, shifting the focus from "how it works" to "how it fails," which is the hallmark of safety-critical engineering.

---

## 2. Alignment with Project Plans

The current state perfectly mirrors the goals in `PLAN.md` and `CONSOLIDATED_PLAN.md`:

- **Phase 1 Implementation:** `llm_parser.py` and `temporal.py` provide the foundational hybrid architecture (LLM for context, Rules for deterministic dates).
- **Documentation Coverage:** The 15+ new Markdown files cover the "Four Pillars" required for clinical software:
    - **Business:** Strategic value in the Australian GP/ED context.
    - **Technical:** LLM prompt engineering and confidence scoring.
    - **Clinical:** Human-in-the-loop and workflow integration.
    - **Compliance:** Australian Privacy Principles and My Health Record (MHR) standards.

---

## 3. Pre-Mortem Analysis & Defensive Engineering

The `PRE_MORTEM.md` identifies 20 failure modes across technical, clinical, and operational domains. My analysis of these risks against the current code identifies several "Safety Guardrails" already in place and some that require immediate attention.

### Built-in Mitigations (Already in Code/Design)
- **Phonetic Hallucinations:** The `llm_parser.py` prompt requires `raw_text` for every extraction. This allows the UI to show the clinician exactly what the AI "heard."
- **Alert Fatigue:** The three-tiered confidence model (>95% Auto-populate, 70-95% Warning, <70% Manual) prevents a "wall of warnings" that clinicians might ignore.
- **Data Sovereignty:** The design documents correctly identify the "Sydney Gap," flagging US-based OpenAI endpoints as "research-only" and targeting Azure OpenAI (Sydney) for production.

### Critical Gaps (Identified Risks)
1. **The "Medicare Billing" Trap (Risk #12):**
    - *Risk:* Automated billing suggestions can lead to "unintentional upcoding" if clinicians blindly approve.
    - *Defense:* Architecture must ensure billing suggestions are logically and visually separated from clinical documentation verification.
2. **Unit Confusion in Vitals (Risk #1):**
    - *Risk:* `llm_parser.py` currently extracts `value with units` as a string. LLMs often fail at unit conversion (e.g., lbs to kg).
    - *Defense:* The schema should be updated to separate `value` (numeric) and `unit` (enum) for rule-based plausibility checking.
3. **MHR Consent Bypass (Risk #11):**
    - *Risk:* Automated uploads to My Health Record without explicit consent.
    - *Defense:* The integration layer requires a hard-coded "Consent State" check that blocks transmission unless an explicit `True` is present.

---

## 4. Technical Strategy Recommendations

To avoid the failures outlined in the Pre-Mortem, I recommend the following adjustments to the Phase 1 & 2 roadmap:

### A. Performance Baselines (UX Killer Mitigation)
We must establish an SLA of **<5 seconds p95** for the end-to-end extraction and verification. If the LLM latency exceeds this, we should move to an **Async Streaming Pattern** where high-confidence items (PII and Dates) are verified while the LLM continues parsing complex medications.

### B. "Uncertainty Detection" over Confidence
Instead of just a 0.0-1.0 score, the parser should flag *why* it is uncertain (e.g., "Mumbled dictation," "Ambiguous temporal reference"). This provides more signal to the clinician during review.

### C. The "Sydney-First" Rule
For the implementation of `_call_llm` in `llm_parser.py`, we should prioritize a client that supports Australian data sovereignty from day one, even if it's a mock client for local development, to prevent accidental PII leakage to US-based endpoints.

---

## 5. Next Steps (Prioritized)

1. **Commit Documentation:** Stage and commit the 15+ Markdown files to establish the "System of Truth" for the architecture.
2. **Task 0.1 (Sample Transcripts):** Create `tests/fixtures/sample_transcripts.json` with the "Edge Case" scenarios identified in the Pre-Mortem (phonetic errors, mixed units, PII).
3. **Task 1.1 (LLM Client Implementation):** Implement a flexible `ExtractionClient` that supports both Mock (for testing) and Azure OpenAI (for Sydney-region processing).

---
*Analysis generated by Gemini CLI based on repository context and high-assurance engineering standards.*
